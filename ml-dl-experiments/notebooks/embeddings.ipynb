{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### article https://jina.ai/news/text-embeddings-fail-to-capture-word-order-and-how-to-fix-it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9423cc4b1d63428ab79720d4dc5ef862",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e49413c2f8744d78b4ad601a2633f3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a588b5aeb7014b88992fecc738c4ffa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_xlm_roberta.py:   0%|          | 0.00/6.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d81a8f69e844291a0fb7e8f7277af93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74bfe400aefa4ac69a8eae558bc02280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_lora.py:   0%|          | 0.00/15.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b894e416e7649e789b79262f96ac78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_xlm_roberta.py:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01eac2a9d8854d85ae07cd5dd6931705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xlm_padding.py:   0%|          | 0.00/10.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14048c10961d491e90f227361c0cd645",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlp.py:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836407c4816e4f718ee05e3937d115a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding.py:   0%|          | 0.00/3.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d6e3c6ad344e958178d306f3e10ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block.py:   0%|          | 0.00/17.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61d014940a534f5fbc892e8666f4fcf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stochastic_depth.py:   0%|          | 0.00/3.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a5e01b9cabb4587976c990eb3f013e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mha.py:   0%|          | 0.00/34.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2efc63cf9b468e92ccecf7e9c2dfce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rotary.py:   0%|          | 0.00/24.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- stochastic_depth.py\n",
      "- mha.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      "- mlp.py\n",
      "- embedding.py\n",
      "- block.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "/Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <EEB3232B-F6A7-3262-948C-BB2F54905803> /Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749b309d515c41a1b89643ff7afd086e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89a374f18344cac9a805a13582350d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7809865b984d4f299c33e33f843ecc2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78b4afb171545828dba62b0051b3ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.708632\n"
     ]
    }
   ],
   "source": [
    "# from https://huggingface.co/jinaai/jina-embeddings-v3\n",
    "\n",
    "from transformers import AutoModel\n",
    "\n",
    "# Initialize the model\n",
    "model = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True, force_download=True)\n",
    "\n",
    "texts = [\n",
    "    \"Follow the white rabbit.\",  # English\n",
    "    \"Sigue al conejo blanco.\",  # Spanish\n",
    "    \"Suis le lapin blanc.\",  # French\n",
    "    \"跟着白兔走。\",  # Chinese\n",
    "    \"اتبع الأرنب الأبيض.\",  # Arabic\n",
    "    \"Folge dem weißen Kaninchen.\",  # German\n",
    "]\n",
    "\n",
    "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
    "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
    "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
    "embeddings = model.encode(texts, task=\"text-matching\")\n",
    "\n",
    "# Compute similarities\n",
    "print(embeddings[0] @ embeddings[1].T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92955387\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Berlin is the capital of Germany\",  # sentence\n",
    "    \"the Germany Berlin is capital of\",  # shuffled\n",
    "]\n",
    "\n",
    "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
    "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
    "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
    "embeddings = model.encode(texts, task=\"text-matching\")\n",
    "\n",
    "# Compute similarities\n",
    "print(embeddings[0] @ embeddings[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94715494\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"She ate dinner before watching the movie\",  # sentence\n",
    "    \"She watched the movie before eating dinner\",  # shuffled\n",
    "]\n",
    "\n",
    "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
    "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
    "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
    "embeddings = model.encode(texts, task=\"text-matching\")\n",
    "\n",
    "# Compute similarities\n",
    "print(embeddings[0] @ embeddings[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.73406297\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"This is a useful model\",  \"This is not a useful model\",  # shuffled\n",
    "]\n",
    "\n",
    "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
    "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
    "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
    "embeddings = model.encode(texts, task=\"text-matching\")\n",
    "\n",
    "# Compute similarities\n",
    "print(embeddings[0] @ embeddings[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74524754\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = [\n",
    "    \"Machine learning is like teaching a computer to learn from experience, just as we do—getting better over time with every piece of data it encounters.\",  # shuffled\n",
    "    \"Like learning teaching a computer from experience, is machine time every we better over piece of it data encounters do.\"\n",
    "]\n",
    "\n",
    "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
    "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
    "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
    "embeddings = model.encode(texts, task=\"text-matching\")\n",
    "\n",
    "# Compute similarities\n",
    "print(embeddings[0] @ embeddings[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89911735\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = [\n",
    "    \"Machine learning is like teaching a computer to learn from experience, just as we do—getting better over time with every piece of data it encounters.\",  # shuffled\n",
    "    \"learning Machine a is like computer teaching to learn experience from , just we as do—getting over better time with it piece every of encounters data.\"\n",
    "]\n",
    "\n",
    "# When calling the `encode` function, you can choose a `task` based on the use case:\n",
    "# 'retrieval.query', 'retrieval.passage', 'separation', 'classification', 'text-matching'\n",
    "# Alternatively, you can choose not to pass a `task`, and no specific LoRA adapter will be used.\n",
    "embeddings = model.encode(texts, task=\"text-matching\")\n",
    "\n",
    "# Compute similarities\n",
    "print(embeddings[0] @ embeddings[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
