{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "import io\n",
    "from qdrant_client import QdrantClient\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from qdrant_client.http import models\n",
    "import ast\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CLIP model and processor for text embeddings\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch16\")\n",
    "\n",
    "# Function to download and load a gzipped JSONL file into a DataFrame with sampling\n",
    "def load_jsonl_to_dataframe(url, sample_size=None):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as f:\n",
    "            df = pd.read_json(f, lines=True)\n",
    "            if sample_size is not None and sample_size < df.shape[0]:\n",
    "                return df.sample(n=sample_size, random_state=1)\n",
    "            else:\n",
    "                return df\n",
    "    else:\n",
    "        raise Exception(f\"Failed to download data: {response.status_code}\")\n",
    "\n",
    "# Function to save DataFrame to a specified directory\n",
    "def save_dataframe_to_csv(df, file_path):\n",
    "    df.to_csv(file_path, index=False)\n",
    "    print(f\"Data saved to {file_path}\")\n",
    "\n",
    "# Function to get text embeddings using CLIP\n",
    "def get_clip_embeddings(texts):\n",
    "    inputs = clip_processor(text=texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        embeddings = clip_model.get_text_features(**inputs)\n",
    "    return embeddings\n",
    "\n",
    "# Function to index data into Qdrant\n",
    "def index_data_into_qdrant(qdrant_client, df, collection_name):\n",
    "    # Create collection if it doesn't exist\n",
    "    qdrant_client.create_collection(\n",
    "            collection_name=collection_name,\n",
    "            vectors_config=models.VectorParams(\n",
    "                size=512,  # Set the size according to your embedding dimension\n",
    "                distance=models.Distance.COSINE  # Use the appropriate distance metric\n",
    "            )\n",
    "        )\n",
    "    print(f\"Collection '{collection_name}' created.\")\n",
    "\n",
    "    # Prepare embeddings for titles and descriptions\n",
    "    titles = df['title'].tolist()\n",
    "    descriptions = df['description'].tolist()\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings = get_clip_embeddings(titles + descriptions)\n",
    "\n",
    "    # Prepare points for Qdrant\n",
    "    points = []\n",
    "    for i, row in df.iterrows():\n",
    "        # Calculate the embedding for the current row\n",
    "        embedding = embeddings[i].tolist()  # Convert tensor to list\n",
    "        \n",
    "        # Prepare the payload with all specified fields\n",
    "        payload = {\n",
    "            \"title\": row['title'],\n",
    "            \"description\": row['description'],\n",
    "            \"images\": row['images'],\n",
    "            \"average_rating\": row['average_rating'],\n",
    "            \"rating_number\": row['rating_number'],\n",
    "            \"price\": f\"${float(row['price']):.2f}\" if pd.notna(row['price']) and isinstance(row['price'], (int, float, str)) and str(row['price']).replace('.', '', 1).isdigit() else \"Price not available\",\n",
    "            \"details\": {key: value for key, value in ast.literal_eval(row['details']).items() if key.strip()} or {\"Not Available\": \"Not Available\"},\n",
    "            \"main_category\": row['main_category'] if pd.notna(row['main_category']) and row['main_category'].strip() else \"Not Available\"\n",
    "        }\n",
    "        \n",
    "        points.append(models.PointStruct(id=i, vector=embedding, payload=payload))\n",
    "    \n",
    "    # Upsert points into Qdrant\n",
    "    qdrant_client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "def check_index_exists(collection_name):\n",
    "    qdrant_client = QdrantClient(url='http://localhost:6333')\n",
    "    # Get all collections\n",
    "    collections = qdrant_client.get_collections().collections\n",
    "    # Check if the specified collection exists\n",
    "    return any(collection.name == collection_name for collection in collections)\n",
    "\n",
    "\n",
    "# Function to get results from Qdrant\n",
    "def get_qdrant_results(query, meta_url, directory, sample_size, collection_name, top_n=5):\n",
    "    qdrant_client = QdrantClient(url='http://localhost:6333')\n",
    "\n",
    "    # Get query embedding\n",
    "    query_embedding = get_clip_embeddings([query])[0].tolist()  # Convert tensor to list\n",
    "\n",
    "    # Save DataFrame to CSV\n",
    "    meta_file_path = os.path.join(directory, \"Digital_Music_Meta.csv\")\n",
    "    if not os.path.exists(meta_file_path):\n",
    "        digital_music_meta_df = load_jsonl_to_dataframe(meta_url, sample_size=sample_size)\n",
    "        save_dataframe_to_csv(digital_music_meta_df, meta_file_path)\n",
    "    else:\n",
    "        digital_music_meta_df = pd.read_csv(meta_file_path)\n",
    "\n",
    "    digital_music_meta_df.fillna('', inplace=True)\n",
    "\n",
    "    if not check_index_exists(collection_name):\n",
    "        # build\n",
    "        index_data_into_qdrant(qdrant_client, digital_music_meta_df, collection_name)\n",
    "\n",
    "    # Search Qdrant\n",
    "    search_result = qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_n\n",
    "    )\n",
    "    \n",
    "    # Convert search results to a DataFrame\n",
    "    results_df = pd.DataFrame([{\n",
    "        'id': hit.id,\n",
    "        'score': hit.score,\n",
    "        **hit.payload\n",
    "    } for hit in search_result])\n",
    "    \n",
    "    return results_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -p 6333:6333 qdrant/qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_name_text = \"text_collection\"\n",
    "check_index_exists(collection_name_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c8/fll6dgp97mnd842vr2qlbjr80000gr/T/ipykernel_23576/3035688260.py:95: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  digital_music_meta_df.fillna('', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'text_collection' created.\n"
     ]
    }
   ],
   "source": [
    "# URLs for the Digital Music category\n",
    "meta_url = \"https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_2023/raw/meta_categories/meta_Digital_Music.jsonl.gz\"\n",
    "\n",
    "filename = 'Digital_Music_Meta.csv'\n",
    "# Specify sample size and directory for saving\n",
    "sample_size = 100000\n",
    "directory = '/Users/rshankar/Downloads/Projects/deep-learning/amazon-search-recommend/data'\n",
    "query = 'data'\n",
    "docs = get_qdrant_results(query, meta_url, directory, sample_size, collection_name_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
