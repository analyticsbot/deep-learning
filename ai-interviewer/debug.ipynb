{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import speech_recognition as sr\n",
    "import requests\n",
    "import random\n",
    "import textstat\n",
    "from openai import OpenAI  # Importing OpenAI to connect with LM Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feedback function using LM Studio\n",
    "def analyze_response(response_text, behavior_role, role, response_criteria):\n",
    "    # Analyze brevity, filler words, and repetition using textstat\n",
    "    feedback = {\n",
    "        \"brevity\": f\"Reading ease score: {textstat.flesch_reading_ease(response_text)}\",\n",
    "        \"filler_words\": \"No obvious filler words detected\"  # Placeholder for a better detection mechanism\n",
    "    }\n",
    "\n",
    "    # Request feedback from LM Studio\n",
    "    client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "    prompt = f\"As a {behavior_role}, imagine you are taking an interview for the role {role}, analyze this answer: '{response_text}'. Focus on: {response_criteria}\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"lmstudio-community/Meta-Llama-3.1-8B-Instruct-GGUF\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an intelligent assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        stream=True,\n",
    "    )\n",
    "    \n",
    "    new_message = {\"role\": \"assistant\", \"content\": \"\"}\n",
    "    \n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            new_message[\"content\"] += chunk.choices[0].delta.content\n",
    "\n",
    "    feedback['LLM_feedback'] = new_message['content'].strip()\n",
    "    \n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-27 22:07:17.994 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/rshankar/anaconda3/envs/cv/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'brevity': 'Reading ease score: 53.38',\n",
       " 'filler_words': 'No obvious filler words detected',\n",
       " 'LLM_feedback': 'Here\\'s my analysis:\\n\\n**Time taken:** The candidate takes approximately 20-25 seconds to provide their response. This is a good pace, but it could be slightly faster considering the question seems to allow for a more open-ended response.\\n\\n**Brevity:**\\nThe candidate\\'s answer is somewhat lengthy (around 45 words) and doesn\\'t immediately get to the point. They start with an introductory phrase (\"Let\\'s build...\") that sets up their idea, but then meanders slightly before getting to the core of their response. A more direct and concise approach would be beneficial.\\n\\n**Filler words:**\\nThe candidate uses a few filler words/phrases (\"this also means,\" \"with an in-person focus designed to support\"), which can make the answer feel less polished.\\n\\n**Repetition:**\\nThere is no clear repetition in this answer, so I\\'ll mark it as \"0\" on that metric.\\n\\n**Answer quality:**\\n\\n* **Clarity:** The candidate\\'s response is generally easy to understand.\\n* **Depth of thought:** While the idea itself (\"building the future of work\") is interesting, the candidate doesn\\'t provide much depth or concrete examples to support their vision. This makes it difficult to assess their level of expertise in ML management.\\n* **Relevance:** The answer seems somewhat disconnected from the role of an ML Manager (which typically involves technical aspects of machine learning). I\\'d expect more focus on how they would apply ML principles to drive innovation and improve work processes.\\n\\n**Overall rating:** 6.5/10\\n\\nFeedback for the candidate:\\n\\n1. Keep your answers concise and focused.\\n2. Practice speaking without filler words/phrases (\"um,\" \"ah,\" etc.).\\n3. Provide concrete examples or supporting details to demonstrate your expertise in ML management.\\n4. Ensure your answer is more relevant to the role of an ML Manager.\\n\\nNow, let\\'s give you some next steps:\\n\\n1. Practice answering behavioral questions with a focus on brevity and clarity.\\n2. Develop a deeper understanding of the ML Manager role and its responsibilities.\\n3. Prepare specific examples that demonstrate your expertise in applying ML principles to drive innovation.'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_text = \"\"\"• Live in the future: Let’s build the future of work that we want, with an in-person focus designed to support a strong, valuable experience for our people who have chosen to work from the office, and a thoughtful and intentional approach to where we invest in remote work. This also means being early adopters of the future products we build to help people feel present together wherever they are.\n",
    "\"\"\"\n",
    "behavior_role = st.text_input(\"Define the role of the LLM (e.g., HR recruiter):\", \"HR recruiter\")\n",
    "response_criteria = st.text_area(\n",
    "    \"Describe the type of response needed (e.g., brevity, time taken, quality):\", \n",
    "    \"Provide feedback on time taken, brevity, filler words, repetition, and answer quality.\"\n",
    ")\n",
    "role = 'ML Manager'\n",
    "analyze_response(response_text, behavior_role, role, response_criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
